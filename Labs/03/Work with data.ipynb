{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 处理数据\n",
        "\n",
        "数据是构建机器学习模型的基础。 在云中集中管理数据，并使在多个工作站上运行试验和训练模型的数据科学家团队能够访问这些数据以及计算目标，这是任何专业数据科学解决方案的重要组成部分。\n",
        "\n",
        "在该笔记本中，你将探索两个用于数据处理的 Azure 机器学习对象：数据存储和数据资产 。\n",
        "\n",
        "## 准备工作\n",
        "\n",
        "需要最新版本的 azureml-ai-ml 包才能运行此笔记本中的代码。 运行下面的单元以验证是否已安装它。\n",
        "\n",
        "> **注意**：\n",
        "> 如果未安装 azure-ai-ml 包，请运行 `pip install azure-ai-ml` 以进行安装。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 连接到工作区\n",
        "\n",
        "安装必需的 SDK 包后，就可以连接到工作区了。\n",
        "\n",
        "若要连接到工作区，我们需要标识符参数 - 订阅 ID、资源组名称和工作区名称。 已为你填写资源组名称和工作区名称。 只需订阅 ID 即可完成命令。\n",
        "\n",
        "若要查找所需的参数，请单击工作室右上角的订阅和工作区名称。 右侧将打开一个窗格。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> 复制订阅 ID，并将“YOUR-SUBSCRIPTION-ID”替换为复制的值。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 列出数据存储\n",
        "\n",
        "创建 Azure 机器学习工作区时，还会创建 Azure 存储帐户。 存储帐户包括 Blob 和文件存储，并作为“数据存储”自动与工作区连接。 可以列出连接到工作区的所有数据存储："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "请注意连接到你之前浏览的“azureml-blobstore-...”容器的 `workspaceblobstore`。 `workspacefilestore` 连接到“code-...”文件共享。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 创建数据存储\n",
        "\n",
        "每当要将另一个 Azure 存储服务与 Azure 机器学习工作区连接时，都可以创建数据存储。 请注意，创建数据存储会在工作区和存储之间创建连接，而不会创建存储服务本身。 \n",
        "\n",
        "若要创建数据存储并连接到（现有的）存储，需要指定：\n",
        "\n",
        "- 一个类，用于指示要连接的存储服务类型。 以下示例连接到 Blob 存储 (`AzureBlobDatastore`)。\n",
        "- `name`：Azure 机器学习工作区中数据存储的显示名称。\n",
        "- `description`：可选说明，用于提供有关数据存储的详细信息。\n",
        "- `account_name`：Azure 存储帐户的名称。\n",
        "- `container_name`：容器的名称，用于在 Azure 存储帐户中存储 Blob。\n",
        "- `credentials`：提供身份验证方法和身份验证凭据。 以下示例使用帐户密钥。\n",
        "\n",
        "**重要提示**： \n",
        "- 将“YOUR-STORAGE-ACCOUNT-NAME”替换为自动创建的存储帐户的名称。 \n",
        "- 将 `account_key` 的 XXXX-XXXX 替换为 Azure 存储帐户的帐户密钥。 \n",
        "\n",
        "请记住，可以通过导航到 [Azure 门户](https://portal.azure.com)来检索帐户密钥，从“访问密钥”选项卡转到存储帐户，复制 key1 或 key2 的密钥值 。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "再次列出数据存储，验证是否已创建名为 `blob_training_data` 的新数据存储："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 创建数据资产\n",
        "\n",
        "若要指向数据存储中的特定文件夹或文件，可以创建数据资产。 数据资产有三种类型：\n",
        "\n",
        "- `URI_FILE` 指向特定文件。\n",
        "- `URI_FOLDER` 指向特定文件夹。\n",
        "- `MLTABLE` 指向 MLTable 文件，该文件指定如何读取文件夹中的一个或多个文件。\n",
        "\n",
        "你将创建所有三种类型的数据资产来体验它们之间的差异。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "若要创建 `URI_FILE` 数据资产，必须指定指向特定文件的路径。 该路径可以是本地路径或云路径。\n",
        "\n",
        "在下面的示例中，你将通过引用本地路径来创建数据资产。 为了确保在使用 Azure 机器学习工作区时数据始终可用，本地文件将自动上传到默认数据存储。 在这种情况下，`diabetes.csv` 文件将上传到 workspaceblobstore 数据存储中的 LocalUpload 文件夹 。 \n",
        "\n",
        "若要从本地文件创建数据资产，请运行以下单元："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "若要创建 `URI_FOLDER` 数据资产，必须指定指向特定文件夹的路径。 该路径可以是本地路径或云路径。\n",
        "\n",
        "在下面的示例中，你将通过引用云路径来创建数据资产。 该路径尚不一定存在。 将数据上传到路径时，会创建该文件夹。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "若要创建 `MLTable` 数据资产，必须指定指向包含 MLTable 文件的文件夹的路径。 该路径可以是本地路径或云路径。 \n",
        "\n",
        "在以下示例中，你将通过引用包含 MLTable 和 CSV 文件的本地路径来创建数据资产。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "若要验证是否已创建新的数据资产，可以再次列出工作区中的所有数据资产："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 读取笔记本中的数据\n",
        "\n",
        "最开始可能希望使用笔记本中的数据资产，以浏览数据并试验机器学习模型。 任何 `URI_FILE` 或 `URI_FOLDER` 类型的数据资产都按正常读取数据的方式进行读取。 例如，若要读取数据资产所指向的 CSV 文件，可以使用 pandas 函数 `read_csv()`。 \n",
        "\n",
        "`MLTable` 类型的数据资产已由 MLTable 文件读取，该文件指定架构以及如何解析数据。 由于数据已读取，因此可以轻松地将 MLTable 数据资产转换为 pandas 数据帧。 \n",
        "\n",
        "需要安装 `mltable` 库（已在终端中进行安装）。 然后，可以将数据资产转换为数据帧并将数据可视化。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 使用作业中的数据\n",
        "\n",
        "使用笔记本进行试验后。 可以使用脚本来训练机器学习模型。 脚本可以作为作业运行，你可以为每个作业指定输入和输出。 \n",
        "\n",
        "可以使用“数据资产”或“数据存储路径”作为作业的输入或输出 。 \n",
        "\n",
        "下面的单元会在 src 文件夹中创建 move-data.py 脚本 。 该脚本使用 `read_csv()` 函数读取输入数据。 然后，脚本将数据以 CSV 文件形式存储在输出路径中。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "若要提交运行 move-data.py 脚本的作业，请运行以下单元。 \n",
        "\n",
        "作业配置为使用数据资产 `diabetes-local`，指向本地 diabetes.csv 文件作为输入。 输出是指向新数据存储 `blob_training_data` 中的文件夹的路径。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}