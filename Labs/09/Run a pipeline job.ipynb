{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 将脚本作为管道作业运行\n",
        "\n",
        "使用管道可将多个步骤分组到一个工作流中。 可使用组件生成管道。 每个组件都反映要运行的 Python 脚本。 组件在 YAML 文件中定义，该文件指定脚本及其运行方式。 \n",
        "\n",
        "## 准备工作\n",
        "\n",
        "需要最新版本的“azureml-ai-ml”包才能运行此笔记本中的代码。 运行下面的单元以验证是否已安装它。\n",
        "\n",
        "> **注意**：\n",
        "> 如果未安装“azure-ai-ml”包，请运行 `pip install azure-ai-ml` 以进行安装。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 连接到工作区\n",
        "\n",
        "安装必需的 SDK 包后，就可以连接到工作区了。\n",
        "\n",
        "若要连接到工作区，我们需要标识符参数 - 订阅 ID、资源组名称和工作区名称。 已为你填写资源组名称和工作区名称。 只需订阅 ID 即可完成命令。\n",
        "\n",
        "若要查找必要的参数，请单击工作区右上角的订阅和工作区名称。 右侧将打开一个窗格。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> 复制订阅 ID，并将“YOUR-SUBSCRIPTION-ID”替换为复制的值。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建脚本\n",
        "\n",
        "通过两个步骤生成管道：\n",
        "\n",
        "1. 准备数据：修复缺失数据并规范化数据。\n",
        "1. 训练模型：训练决策树分类模型。\n",
        "\n",
        "运行以下单元以创建“src”文件夹和两个脚本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 定义组件\n",
        "\n",
        "若要定义组件，需要指定：\n",
        "\n",
        "- 元数据：名称、显示名称、版本、说明、类型等。元数据可帮助描述和管理组件    。\n",
        "- 接口：输入和输出 。 例如，模型训练组件将训练数据和正则化率作为输入，并生成训练的模型文件作为输出。 \n",
        "- 命令、代码和环境：用于运行组件的命令、代码和环境  。 命令是用于执行组件的 shell 命令。 代码通常指源代码目录。 环境可以是 AzureML 环境（特选或自定义创建）、docker 映像或 conda 环境。\n",
        "\n",
        "运行以下单元，为要作为管道步骤运行的每个组件创建 YAML。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 加载组件\n",
        "\n",
        "定义每个组件后，可通过引用 YAML 文件来加载组件。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 构建管道\n",
        "\n",
        "创建并加载组件后，可生成管道。 你将这两个组件组合到一个管道中。 首先，需要运行 `prep_data` 组件。 第一个组件的输出应该是第二个组件 `train_decision_tree` 的输入，第二个组件将训练模型。\n",
        "\n",
        "`diabetes_classification` 函数表示完整的管道。 该函数需要一个输入参数：`pipeline_job_input`。 在设置过程中创建了一个数据资产。 你将使用已注册的数据资产作为管道输入。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "可通过打印 `pipeline_job` 对象来检索管道作业的配置："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "可通过引用参数并指定新值来更改管道作业配置的任何参数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 提交管道作业\n",
        "\n",
        "最后，生成管道并将管道作业配置为根据需要运行后，可提交管道作业："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the components\n",
        "\n",
        "To define the component you need to specify:\n",
        "\n",
        "- **Metadata**: *name*, *display name*, *version*, *description*, *type* etc. The metadata helps to describe and manage the component.\n",
        "- **Interface**: *inputs* and *outputs*. For example, a model training component will take training data and the regularization rate as input, and generate a trained model file as output. \n",
        "- **Command, code & environment**: the *command*, *code* and *environment* to run the component. Command is the shell command to execute the component. Code usually refers to a source code directory. Environment could be an AzureML environment (curated or custom created), docker image or conda environment.\n",
        "\n",
        "Run the following cells to create a YAML for each component you want to run as a pipeline step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile prep-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare training data\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  input_data: \n",
        "    type: uri_file\n",
        "outputs:\n",
        "  output_data:\n",
        "    type: uri_file\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python prep-data.py \n",
        "  --input_data ${{inputs.input_data}}\n",
        "  --output_data ${{outputs.output_data}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train a decision tree classifier model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  training_data: \n",
        "    type: uri_file\n",
        "  reg_rate:\n",
        "    type: number\n",
        "    default: 0.01\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python train-model.py \n",
        "  --training_data ${{inputs.training_data}} \n",
        "  --reg_rate ${{inputs.reg_rate}} \n",
        "  --model_output ${{outputs.model_output}} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the components\n",
        "\n",
        "Now that you have defined each component, you can load the components by referring to the YAML files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "prep_data = load_component(source=parent_dir + \"./prep-data.yml\")\n",
        "train_decision_tree = load_component(source=parent_dir + \"./train-model.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the pipeline\n",
        "\n",
        "After creating and loading the components, you can build the pipeline. You'll compose the two components into a pipeline. First, you'll want the `prep_data` component to run. The output of the first component should be the input of the second component `train_decision_tree`, which will train the model.\n",
        "\n",
        "The `diabetes_classification` function represents the complete pipeline. The function expects one input variable: `pipeline_job_input`. A data asset was created during setup. You'll use the registered data asset as the pipeline input. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def diabetes_classification(pipeline_job_input):\n",
        "    clean_data = prep_data(input_data=pipeline_job_input)\n",
        "    train_model = train_decision_tree(training_data=clean_data.outputs.output_data)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\": clean_data.outputs.output_data,\n",
        "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
        "    }\n",
        "\n",
        "pipeline_job = diabetes_classification(Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-data:1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can retrieve the configuration of the pipeline job by printing the `pipeline_job` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can change any parameter of the pipeline job configuration by referring to the parameter and specifying the new value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# change the output mode\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
        "# set pipeline level compute\n",
        "pipeline_job.settings.default_compute = \"aml-cluster\"\n",
        "# set pipeline level datastore\n",
        "pipeline_job.settings.default_datastore = \"workspaceblobstore\"\n",
        "\n",
        "# print the pipeline job again to review the changes\n",
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the pipeline job\n",
        "\n",
        "Finally, when you've built the pipeline and configured the pipeline job to run as required, you can submit the pipeline job:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"pipeline_diabetes\"\n",
        ")\n",
        "pipeline_job"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}