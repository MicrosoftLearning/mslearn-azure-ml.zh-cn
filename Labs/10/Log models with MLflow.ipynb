{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 使用 MLflow 记录模型\n",
        "\n",
        "可以使用 Azure 机器学习中的 MLflow 来记录模型。 将模型记录为模型而不是项目时，输出目录中会创建一个 MLmodel。 MLmodel 文件包含所有模型元数据。 可以在记录模型时自定义模型的签名。\n",
        "\n",
        "## 准备工作\n",
        "\n",
        "需要最新版本的“azureml-ai-ml”包才能运行此笔记本中的代码。 运行下面的单元以验证是否已安装它。\n",
        "\n",
        "> **注意**：\n",
        "> 如果未安装“azure-ai-ml”包，请运行 `pip install azure-ai-ml` 以进行安装。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 连接到工作区\n",
        "\n",
        "安装必需的 SDK 包后，就可以连接到工作区了。\n",
        "\n",
        "若要连接到工作区，我们需要标识符参数 - 订阅 ID、资源组名称和工作区名称。 已为你填写资源组名称和工作区名称。 只需订阅 ID 即可完成命令。\n",
        "\n",
        "若要查找所需的参数，请单击工作室右上角的订阅和工作区名称。 右侧将打开一个窗格。\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> 复制订阅 ID，并将“YOUR-SUBSCRIPTION-ID”替换为复制的值。 </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用 MLflow 自动记录日志\n",
        "\n",
        "使用自动日志记录时，会自动记录模型。 会推断出模型风格和架构。 \n",
        "\n",
        "运行以下单元格，在 src 文件夹中创建 train-model-autolog.py 脚本 。 该脚本通过使用同一文件夹中的 diabetes.csv 文件（作为参数传递）来训练分类模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "现在可以将脚本作为命令作业提交。\n",
        "\n",
        "运行下面的单元格来训练模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "在工作室中导航到“diabetes-train-autolog”作业，浏览所运行的命令作业的概述。 在“输出 + 日志”选项卡中找到记录的项目。选择 `model` 文件夹以查找 `MLmodel` 文件并浏览其内容。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在使用自动日志记录的情况下指定风格\n",
        "\n",
        "使用自动日志记录时依然可以指定模型的风格。 在此示例中，模型的风格是 scikit-learn。\n",
        "\n",
        "运行以下单元格，在 src 文件夹中创建 train-model-sklearn.py 脚本 。 该脚本通过使用同一文件夹中的 diabetes.csv 文件（作为参数传递）来训练分类模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "现在可以将脚本作为命令作业提交。\n",
        "\n",
        "运行下面的单元格来训练模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "在工作室中导航到“diabetes-train-sklearn”作业，浏览所运行的命令作业的概述。 在“输出 + 日志”选项卡中找到记录的项目。选择 `model` 文件夹以查找 `MLmodel` 文件并浏览其内容。\n",
        "\n",
        "比较前两个运行的 `MLmodel` 文件。 你会发现它们是相同的，这表明 MLflow 的自动日志记录功能正确地推断出了模型的风格。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用推断的签名自定义模型\n",
        "\n",
        "使用自动日志记录时，可以手动记录模型。 使用“log_models=False”，自动日志记录就不会记录模型。 你将通过从训练数据集和预测结果推断签名来创建签名。 最后将记录 scikit-learn 模型。\n",
        "\n",
        "运行以下单元格，在 src 文件夹中创建 train-model-infer.py 脚本 。 该脚本通过使用同一文件夹中的 diabetes.csv 文件（作为参数传递）来训练分类模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "现在可以将脚本作为命令作业提交。\n",
        "\n",
        "运行下面的单元格来训练模型。 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在工作室中导航到“diabetes-train-infer”作业，浏览所运行的命令作业的概述。 在“输出 + 日志”选项卡中找到记录的项目。选择 `model` 文件夹以查找 `MLmodel` 文件并浏览其内容。\n",
        "\n",
        "通过前两个运行比较 `MLmodel` 文件。 你会发现它们是一样的，这表明 MLflow 的自动日志记录功能也能正确地推断出模型的签名。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用定义的签名自定义模型\n",
        "\n",
        "使用自动日志记录时，可以手动记录模型。 使用“log_models=False”，自动日志记录就不会记录模型。 你将通过从训练数据集和预测结果推断签名来创建签名。 最后将记录 scikit-learn 模型。\n",
        "\n",
        "运行以下单元格，在 src 文件夹中创建 train-model-infer.py 脚本 。 该脚本通过使用同一文件夹中的 diabetes.csv 文件（作为参数传递）来训练分类模型。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "现在可以将脚本作为命令作业提交。\n",
        "\n",
        "运行下面的单元格来训练模型。 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在工作室中导航到“diabetes-train-signature”作业，浏览所运行的命令作业的概述。 在“输出 + 日志”选项卡中找到记录的项目。选择 `model` 文件夹以查找 `MLmodel` 文件并浏览其内容。\n",
        "\n",
        "通过前面的运行比较 `MLmodel` 文件。 你会注意到签名与之前的运行不同。 前文的运行使用基于张量的签名，而最新的运行使用基于列的签名。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## 注册模型\n",
        "\n",
        "选择要部署的模型时，可以先注册该模型。 \n",
        "\n",
        "若要注册最新模型，请引用作业运行的名称。 通过将模型注册为 MLflow 模型，可以在以后轻松地部署它。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在工作室中导航到“模型”页。 在模型列表中找到并选择 `mlflow-diabetes` 模型以进一步地浏览。\n",
        "\n",
        "- 在 `mlflow-diabetes` 模型的“详细信息”选项卡中，可以看到它是 `MLFLOW` 类型模型，以及训练该模型的作业。\n",
        "- 在“项目”选项卡中，可以找到包含 `MLmodel` 文件的目录。\n",
        "\n",
        "如果要进一步探索模型的行为，可以选择将模型部署到实时终结点。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customize the model with an inferred signature\n",
        "\n",
        "You can manually log the model when using autologging. By using 'log_models=False', autologging will not log the model. You'll create a signature by inferring it from the training dataset and predicted results. And finally, you'll log the scikit-learn model.\n",
        "\n",
        "Run the following cell to create the **train-model-infer.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/train-model-infer.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "def main(args):\n",
        "    # enable autologging\n",
        "    mlflow.autolog(log_models=False)\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    y_hat = eval_model(model, X_test, y_test)\n",
        "\n",
        "    # create the signature by inferring it from the datasets\n",
        "    signature = infer_signature(X_train, y_hat)\n",
        "\n",
        "    # manually log the model\n",
        "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        " \n",
        "    return y_hat\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-infer.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-infer\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Studio, navigate to the **diabetes-train-infer** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
        "\n",
        "Compare the `MLmodel` files with the previous two runs. You'll notice that they're all the same, indicating that MLflow's autolog feature correctly inferred the model's signature too."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customize the model with a defined signature\n",
        "\n",
        "You can manually log the model when using autologging. By using 'log_models=False', autologging will not log the model. You'll create a signature by inferring it from the training dataset and predicted results. And finally, you'll log the scikit-learn model.\n",
        "\n",
        "Run the following cell to create the **train-model-infer.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/train-model-signature.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import ModelSignature\n",
        "from mlflow.types.schema import Schema, ColSpec\n",
        "\n",
        "def main(args):\n",
        "    # enable autologging\n",
        "    mlflow.autolog(log_models=False)\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    y_hat = eval_model(model, X_test, y_test)\n",
        "\n",
        "    # create the signature manually\n",
        "    input_schema = Schema([\n",
        "    ColSpec(\"integer\", \"Pregnancies\"),\n",
        "    ColSpec(\"integer\", \"PlasmaGlucose\"),\n",
        "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
        "    ColSpec(\"integer\", \"TricepsThickness\"),\n",
        "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
        "    ColSpec(\"integer\", \"SerumInsulin\"),\n",
        "    ColSpec(\"double\", \"BMI\"),\n",
        "    ColSpec(\"double\", \"DiabetesPedigree\"),\n",
        "    ColSpec(\"integer\", \"Age\"),\n",
        "    ])\n",
        "\n",
        "    output_schema = Schema([ColSpec(\"boolean\")])\n",
        "\n",
        "    # Create the signature object\n",
        "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
        "\n",
        "    # manually log the model\n",
        "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        " \n",
        "    return y_hat\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-signature\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Studio, navigate to the **diabetes-train-signature** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
        "\n",
        "Compare the `MLmodel` files with the previous runs. You'll notice that the signature is different from the previous runs. Previous runs used tensor-based signatures, whereas the latest run used a column-based signature."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the model\n",
        "\n",
        "When you choose a model you want to deploy, you can first register the model. \n",
        "\n",
        "To register the latest model, you'll refer to the name of the job run. By registering the model as an MLflow model, you can easily deploy it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "job_name = returned_job.name\n",
        "\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
        "    name=\"mlflow-diabetes\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "# Uncomment after adding required details above\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Studio, navigate to the **Models** page. In the model list, find the `mlflow-diabetes` model and select it to explore it further.\n",
        "\n",
        "- In the **Details** tab of the `mlflow-diabetes` model, you can review that it's a `MLFLOW` type model and the job that trained the model.\n",
        "- In the **Artifacts** tab you can find the directory with the `MLmodel` file.\n",
        "\n",
        "If you want to explore the model's behavior further, you can **optionally** choose to deploy the model to a real-time endpoint."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}